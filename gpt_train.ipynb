{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1420f1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Config loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.transformers import DecoderOnlyTransformer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import gc\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import wandb\n",
    "import yaml\n",
    "from data.datasets import CFGDataset, verify_dataloader\n",
    "from trainers.GPT_trainer import GPT_Trainer\n",
    "from trainers.utils import create_optimizer, create_scheduler\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "#Read config yaml file\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "print(f\"Config loaded successfully.\")\n",
    "\n",
    "\n",
    "import os\n",
    "os.system(\"export WANDB_DIR=\\tmp\")\n",
    "#os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b483202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.CFG_parsers import CFGParser\n",
    "from data.grammars import GRAMMAR_SIMPLE\n",
    "parser = CFGParser(GRAMMAR_SIMPLE)\n",
    "parser.is_valid(\"3213212123\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f46d0e9",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b809426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying dataloader...\n",
      "Number of batches:  40669\n",
      "Total number of tokens:  1.998977e+09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example batch shapes (shifted, golden):  torch.Size([96, 512]) torch.Size([96, 512])\n",
      "__________________________________________________\n",
      "Verifying dataloader...\n",
      "Number of batches:  4518\n",
      "Total number of tokens:  2.221086e+08\n",
      "Example batch shapes (shifted, golden):  torch.Size([96, 512]) torch.Size([96, 512])\n"
     ]
    }
   ],
   "source": [
    "train_dataset =  CFGDataset(\n",
    "    data_file=\"cfg_sentences_train_cfg3b.npy\", \n",
    "    batch_size = config[\"data\"][\"batch_size\"],\n",
    "    seq_len = config[\"data\"][\"seq_len\"],\n",
    "    eos_token = config[\"data\"][\"eos_token\"],\n",
    "    sos_token = config[\"data\"][\"sos_token\"],\n",
    "    ) \n",
    "\n",
    "val_dataset =  CFGDataset(\n",
    "    data_file=\"cfg_sentences_val_cfg3b.npy\", \n",
    "    \n",
    "    batch_size = config[\"data\"][\"batch_size\"],\n",
    "    seq_len = config[\"data\"][\"seq_len\"],\n",
    "    eos_token = config[\"data\"][\"eos_token\"],\n",
    "    sos_token = config[\"data\"][\"sos_token\"],\n",
    "    ) \n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size = None, \n",
    "                          num_workers=config[\"data\"][\"NUM_WORKERS\"] if device == \"cuda\" else 0, \n",
    "                          pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                        batch_size=None, \n",
    "                        num_workers=config[\"data\"][\"NUM_WORKERS\"] if device == \"cuda\" else 0,\n",
    "                        pin_memory=True)\n",
    "\n",
    "verify_dataloader(train_loader)\n",
    "print(\"_\"*50)\n",
    "verify_dataloader(val_loader)\n",
    "#print(\"=\"*50)\n",
    "#print(\"Verify Validation DataLoader\")\n",
    "#verify_dataloader(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff351c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of shifted_transcripts :  torch.Size([96, 512])\n",
      "Shape of golden_transcripts  :  torch.Size([96, 512])\n",
      "Total parameters in the model: 42,532,613\n"
     ]
    }
   ],
   "source": [
    "model_config = {}\n",
    "model_config = config['model'].copy()\n",
    "\n",
    "model_config.update({\n",
    "    'num_classes': config[\"data\"][\"vocab_size\"] +2 ,#include SOS and ESO tolen\n",
    "    'seq_len': config[\"data\"][\"seq_len\"],\n",
    "    })\n",
    "\n",
    "model = DecoderOnlyTransformer(**model_config)\n",
    "\n",
    "for batch in train_loader:\n",
    "    shifted_transcripts, golden_transcripts = batch\n",
    "    print(\"Shape of shifted_transcripts : \", shifted_transcripts.shape)\n",
    "    print(\"Shape of golden_transcripts  : \", golden_transcripts.shape)\n",
    "    break\n",
    "\n",
    "#model_stats = summary(model, input_data=[shifted_transcripts])\n",
    "#print(model_stats)\n",
    "print(f\"Total parameters in the model: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "#torch._dynamo.config.skip_nnmodule_hook_guards = False\n",
    "#model = torch.compile(model, mode=\"default\", fullgraph=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50faa61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlucasfragara\u001b[0m (\u001b[33mteamlsfr\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/ocean/projects/cis250019p/sfragara/lstm/wandb/run-20250422_223322-s9uoxvio</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/teamlsfr/Thesis/runs/s9uoxvio' target=\"_blank\">full_rope</a></strong> to <a href='https://wandb.ai/teamlsfr/Thesis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/teamlsfr/Thesis' target=\"_blank\">https://wandb.ai/teamlsfr/Thesis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/teamlsfr/Thesis/runs/s9uoxvio' target=\"_blank\">https://wandb.ai/teamlsfr/Thesis/runs/s9uoxvio</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”§ Configuring Optimizer:\n",
      "â”œâ”€â”€ Type: ADAMW\n",
      "â”œâ”€â”€ Base LR: 0.0007\n",
      "â”œâ”€â”€ Weight Decay: 0.1\n",
      "â”œâ”€â”€ Parameter Groups:\n",
      "â”‚   â”œâ”€â”€ Group: self_attn\n",
      "â”‚   â”‚   â”œâ”€â”€ LR: 0.0007\n",
      "â”‚   â”‚   â””â”€â”€ Patterns: []\n",
      "â”‚   â”œâ”€â”€ Group: ffn\n",
      "â”‚   â”‚   â”œâ”€â”€ LR: 0.0007\n",
      "â”‚   â”‚   â””â”€â”€ Patterns: []\n",
      "â”‚   â””â”€â”€ Default Group (unmatched parameters)\n",
      "â””â”€â”€ AdamW Specific:\n",
      "    â”œâ”€â”€ Betas: [0.9, 0.98]\n",
      "    â”œâ”€â”€ Epsilon: 1e-08\n",
      "    â””â”€â”€ AMSGrad: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/home/sfragara/.conda/envs/env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Configuring Learning Rate Scheduler:\n",
      "â”œâ”€â”€ Type: COSINE\n",
      "â”œâ”€â”€ Cosine Annealing Settings:\n",
      "â”‚   â”œâ”€â”€ T_max: 40669 steps\n",
      "â”‚   â””â”€â”€ Min LR: 1e-08\n",
      "â””â”€â”€ Warmup: Disabled\n"
     ]
    }
   ],
   "source": [
    "from trainers.utils.create_scheduler import plot_lr_schedule\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "#wandb.finish()\n",
    "trainer = GPT_Trainer(\n",
    "    model = model, \n",
    "    config = config,\n",
    "    config_file = \"config.yaml\",\n",
    "    run_name = \"full_rope\", \n",
    "    device = device\n",
    ")\n",
    "wandb.watch(trainer.model, log=\"all\")\n",
    "\n",
    "trainer.optimizer = create_optimizer.create_optimizer(\n",
    "    model = model, \n",
    "    opt_config = config[\"optimizer\"]\n",
    ")\n",
    "\n",
    "trainer.scheduler = create_scheduler.create_scheduler(\n",
    "    optimizer=trainer.optimizer,\n",
    "    scheduler_config=config['scheduler'],\n",
    "    train_loader=train_loader,\n",
    "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
    ")\n",
    "\n",
    "#plot_lr_schedule(trainer.scheduler, num_epochs=len(train_loader), train_loader=train_loader)\n",
    "\n",
    "#trainer.load_checkpoint(\"/ocean/projects/cis250019p/sfragara/lstm/expts/test/checkpoints/checkpoint-best-metric-model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c5c200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       1:30:17,  7.42it/s, acc_step=1/1, ce_loss_token=1.3246, lr=0.000700, perplexity_token=3.7608]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb metrics being logged:  {'train/ce_loss_token': 1.3246285346691717, 'train/perplexity_token': 3.7607882022857666, 'val/ce_loss_token': 1.1964159235358238, 'val/perplexity_token': 3.3082385063171387, 'learning_rate': 0.0006997379248477051}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 500):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 1.3246\n",
      "â”‚   â””â”€â”€ perplexity_token: 3.7608\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 1.1964\n",
      "    â””â”€â”€ perplexity_token: 3.3082\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       2:42:45,  4.06it/s, acc_step=1/1, ce_loss_token=1.2014, lr=0.000699, perplexity_token=3.3247]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 1.201375137556802, 'train/perplexity_token': 3.324685573577881, 'val/ce_loss_token': 1.0131168588995934, 'val/perplexity_token': 2.754171848297119, 'learning_rate': 0.0006989541814204076}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 1000):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 1.2014\n",
      "â”‚   â””â”€â”€ perplexity_token: 3.3247\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 1.0131\n",
      "    â””â”€â”€ perplexity_token: 2.7542\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         7.40it/s, acc_step=1/1, ce_loss_token=1.1280, lr=0.000698, perplexity_token=3.0894]        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 1.1279729470501416, 'train/perplexity_token': 3.089387893676758, 'val/ce_loss_token': 0.9538229033350945, 'val/perplexity_token': 2.595613479614258, 'learning_rate': 0.0006976499377227822}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 1500):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 1.1280\n",
      "â”‚   â””â”€â”€ perplexity_token: 3.0894\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.9538\n",
      "    â””â”€â”€ perplexity_token: 2.5956\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         4.37it/s, acc_step=1/1, ce_loss_token=1.0752, lr=0.000696, perplexity_token=2.9305]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 1.0751766070075657, 'train/perplexity_token': 2.9305102825164795, 'val/ce_loss_token': 0.910547249019146, 'val/perplexity_token': 2.485682487487793, 'learning_rate': 0.0006958271391933999}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 2000):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 1.0752\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.9305\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.9105\n",
      "    â””â”€â”€ perplexity_token: 2.4857\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         7.40it/s, acc_step=1/1, ce_loss_token=1.0326, lr=0.000693, perplexity_token=2.8085]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 1.0326489400072414, 'train/perplexity_token': 2.80849552154541, 'val/ce_loss_token': 0.8485343288630247, 'val/perplexity_token': 2.3362202644348145, 'learning_rate': 0.0006934885047586219}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 2500):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 1.0326\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.8085\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.8485\n",
      "    â””â”€â”€ perplexity_token: 2.3362\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         4.39it/s, acc_step=1/1, ce_loss_token=1.0010, lr=0.000691, perplexity_token=2.7210]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 1.0010097592284544, 'train/perplexity_token': 2.7210278511047363, 'val/ce_loss_token': 0.8329426404088736, 'val/perplexity_token': 2.300077199935913, 'learning_rate': 0.0006906375227769823}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 3000):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 1.0010\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.7210\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.8329\n",
      "    â””â”€â”€ perplexity_token: 2.3001\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         7.40it/s, acc_step=1/1, ce_loss_token=0.9764, lr=0.000687, perplexity_token=2.6550]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.9764482704137809, 'train/perplexity_token': 2.6550097465515137, 'val/ce_loss_token': 0.8235246017575264, 'val/perplexity_token': 2.2785165309906006, 'learning_rate': 0.0006872784458358806}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 3500):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.9764\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.6550\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.8235\n",
      "    â””â”€â”€ perplexity_token: 2.2785\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         4.36it/s, acc_step=1/1, ce_loss_token=0.9569, lr=0.000683, perplexity_token=2.6036]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.9568777784232169, 'train/perplexity_token': 2.6035549640655518, 'val/ce_loss_token': 0.8162614721804857, 'val/perplexity_token': 2.2620272636413574, 'learning_rate': 0.0006834162844083303}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 4000):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.9569\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.6036\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.8163\n",
      "    â””â”€â”€ perplexity_token: 2.2620\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         7.41it/s, acc_step=1/1, ce_loss_token=0.9396, lr=0.000679, perplexity_token=2.5590]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.9396313394315771, 'train/perplexity_token': 2.559037923812866, 'val/ce_loss_token': 0.7962020896375179, 'val/perplexity_token': 2.217104434967041, 'learning_rate': 0.0006790567993792218}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 4500):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.9396\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.5590\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7962\n",
      "    â””â”€â”€ perplexity_token: 2.2171\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         4.34it/s, acc_step=1/1, ce_loss_token=0.9253, lr=0.000674, perplexity_token=2.5226]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.9252805511037533, 'train/perplexity_token': 2.522575855255127, 'val/ce_loss_token': 0.8026994336396456, 'val/perplexity_token': 2.2315568923950195, 'learning_rate': 0.0006742064934522636}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 5000):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.9253\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.5226\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.8027\n",
      "    â””â”€â”€ perplexity_token: 2.2316\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         7.40it/s, acc_step=1/1, ce_loss_token=0.9131, lr=0.000669, perplexity_token=2.4920]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.9130734207087963, 'train/perplexity_token': 2.491969585418701, 'val/ce_loss_token': 0.7884537652134895, 'val/perplexity_token': 2.1999921798706055, 'learning_rate': 0.0006688726014504025}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 5500):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.9131\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.4920\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7885\n",
      "    â””â”€â”€ perplexity_token: 2.2000\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         4.29it/s, acc_step=1/1, ce_loss_token=0.9025, lr=0.000663, perplexity_token=2.4658]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.9025196654561003, 'train/perplexity_token': 2.465808153152466, 'val/ce_loss_token': 0.7842774074524641, 'val/perplexity_token': 2.1908233165740967, 'learning_rate': 0.0006630630795242126}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 6000):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.9025\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.4658\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7843\n",
      "    â””â”€â”€ perplexity_token: 2.1908\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         7.40it/s, acc_step=1/1, ce_loss_token=0.8929, lr=0.000657, perplexity_token=2.4423]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8929395340640918, 'train/perplexity_token': 2.442298173904419, 'val/ce_loss_token': 0.7755730114877224, 'val/perplexity_token': 2.1718363761901855, 'learning_rate': 0.0006567865932843148}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 6500):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8929\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.4423\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7756\n",
      "    â””â”€â”€ perplexity_token: 2.1718\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         4.37it/s, acc_step=1/1, ce_loss_token=0.8846, lr=0.000650, perplexity_token=2.4220]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8845842305446859, 'train/perplexity_token': 2.4219772815704346, 'val/ce_loss_token': 0.7744367402046919, 'val/perplexity_token': 2.169369697570801, 'learning_rate': 0.0006500525048755697}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 7000):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8846\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.4220\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7744\n",
      "    â””â”€â”€ perplexity_token: 2.1694\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         7.39it/s, acc_step=1/1, ce_loss_token=0.8773, lr=0.000643, perplexity_token=2.4043]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8772654486821343, 'train/perplexity_token': 2.404315948486328, 'val/ce_loss_token': 0.774933610111475, 'val/perplexity_token': 2.170448064804077, 'learning_rate': 0.0006428708590122884}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 7500):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8773\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.4043\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7749\n",
      "    â””â”€â”€ perplexity_token: 2.1704\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8708, lr=0.000635, perplexity_token=2.3888]                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8707922700568596, 'train/perplexity_token': 2.3888027667999268, 'val/ce_loss_token': 0.7708772197365761, 'val/perplexity_token': 2.1616616249084473, 'learning_rate': 0.0006352523679953224}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 8000):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8708\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.3888\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7709\n",
      "    â””â”€â”€ perplexity_token: 2.1617\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8648, lr=0.000627, perplexity_token=2.3744]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8647592300780309, 'train/perplexity_token': 2.374434232711792, 'val/ce_loss_token': 0.7669652830809355, 'val/perplexity_token': 2.153221845626831, 'learning_rate': 0.0006272083957333581}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 8500):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8648\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.3744\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7670\n",
      "    â””â”€â”€ perplexity_token: 2.1532\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8594, lr=0.000619, perplexity_token=2.3617]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8593781714359399, 'train/perplexity_token': 2.36169171333313, 'val/ce_loss_token': 0.7659981604665518, 'val/perplexity_token': 2.1511404514312744, 'learning_rate': 0.0006187509407922598}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 9000):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8594\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.3617\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7660\n",
      "    â””â”€â”€ perplexity_token: 2.1511\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8546, lr=0.000610, perplexity_token=2.3503]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8545562778193252, 'train/perplexity_token': 2.3503313064575195, 'val/ce_loss_token': 0.7700695339590311, 'val/perplexity_token': 2.159916400909424, 'learning_rate': 0.0006098926184977486}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 9500):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8546\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.3503\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7701\n",
      "    â””â”€â”€ perplexity_token: 2.1599\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8502, lr=0.000601, perplexity_token=2.3401]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8502063772020644, 'train/perplexity_token': 2.340129852294922, 'val/ce_loss_token': 0.7697925828397274, 'val/perplexity_token': 2.159318208694458, 'learning_rate': 0.000600646642118101}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 10000):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8502\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.3401\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7698\n",
      "    â””â”€â”€ perplexity_token: 2.1593\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8461, lr=0.000591, perplexity_token=2.3306]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8461049551986964, 'train/perplexity_token': 2.3305516242980957, 'val/ce_loss_token': 0.7635428719222546, 'val/perplexity_token': 2.1458654403686523, 'learning_rate': 0.0005910268031549461}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 10500):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8461\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.3306\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7635\n",
      "    â””â”€â”€ perplexity_token: 2.1459\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8424, lr=0.000581, perplexity_token=2.3219]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8423731838309887, 'train/perplexity_token': 2.3218705654144287, 'val/ce_loss_token': 0.7654754463583231, 'val/perplexity_token': 2.1500163078308105, 'learning_rate': 0.0005810474507715675}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 11000):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8424\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.3219\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7655\n",
      "    â””â”€â”€ perplexity_token: 2.1500\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8390, lr=0.000571, perplexity_token=2.3141]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8390003393115338, 'train/perplexity_token': 2.3140525817871094, 'val/ce_loss_token': 0.7642270661890507, 'val/perplexity_token': 2.147334098815918, 'learning_rate': 0.0005707234703893648}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 11500):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8390\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.3141\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7642\n",
      "    â””â”€â”€ perplexity_token: 2.1473\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8361, lr=0.000560, perplexity_token=2.3074]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.836119909031611, 'train/perplexity_token': 2.307396650314331, 'val/ce_loss_token': 0.7679433897137642, 'val/perplexity_token': 2.1553289890289307, 'learning_rate': 0.0005600702614844415}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 12000):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8361\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.3074\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7679\n",
      "    â””â”€â”€ perplexity_token: 2.1553\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8337, lr=0.000549, perplexity_token=2.3019]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8337310784512086, 'train/perplexity_token': 2.301891326904297, 'val/ce_loss_token': 0.774030301719904, 'val/perplexity_token': 2.1684885025024414, 'learning_rate': 0.000549103714617398}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 12500):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8337\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.3019\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7740\n",
      "    â””â”€â”€ perplexity_token: 2.1685\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8316, lr=0.000538, perplexity_token=2.2970]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8315836658625224, 'train/perplexity_token': 2.2969534397125244, 'val/ce_loss_token': 0.7748826462775469, 'val/perplexity_token': 2.170337438583374, 'learning_rate': 0.0005378401877306342}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 13000):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8316\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.2970\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7749\n",
      "    â””â”€â”€ perplexity_token: 2.1703\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8295, lr=0.000526, perplexity_token=2.2922]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8295305043262479, 'train/perplexity_token': 2.2922422885894775, 'val/ce_loss_token': 0.7758742179721594, 'val/perplexity_token': 2.1724905967712402, 'learning_rate': 0.0005262964817484706}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 13500):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8295\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.2922\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7759\n",
      "    â””â”€â”€ perplexity_token: 2.1725\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8275, lr=0.000514, perplexity_token=2.2877]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8275469545423708, 'train/perplexity_token': 2.2876999378204346, 'val/ce_loss_token': 0.7722153514623642, 'val/perplexity_token': 2.1645562648773193, 'learning_rate': 0.0005144898155165267}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 14000):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8275\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.2877\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7722\n",
      "    â””â”€â”€ perplexity_token: 2.1646\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8256, lr=0.000502, perplexity_token=2.2832]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8255689957332434, 'train/perplexity_token': 2.283179521560669, 'val/ce_loss_token': 0.765829760581255, 'val/perplexity_token': 2.150778293609619, 'learning_rate': 0.0005024378001177138}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 14500):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8256\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.2832\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7658\n",
      "    â””â”€â”€ perplexity_token: 2.1508\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8236, lr=0.000490, perplexity_token=2.2787]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8236229158935447, 'train/perplexity_token': 2.278740644454956, 'val/ce_loss_token': 0.7687706556171179, 'val/perplexity_token': 2.1571128368377686, 'learning_rate': 0.0004901584126031537}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 15000):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8236\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.2787\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7688\n",
      "    â””â”€â”€ perplexity_token: 2.1571\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8220, lr=0.000478, perplexity_token=2.2751]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8220145363291189, 'train/perplexity_token': 2.275078296661377, 'val/ce_loss_token': 0.7676709219813347, 'val/perplexity_token': 2.1547417640686035, 'learning_rate': 0.0004776699691772117}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 15500):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8220\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.2751\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7677\n",
      "    â””â”€â”€ perplexity_token: 2.1547\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8205, lr=0.000465, perplexity_token=2.2716]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8204981055746048, 'train/perplexity_token': 2.2716310024261475, 'val/ce_loss_token': 0.7692995630204678, 'val/perplexity_token': 2.1582539081573486, 'learning_rate': 0.00046499109787665133}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 16000):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8205\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.2716\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7693\n",
      "    â””â”€â”€ perplexity_token: 2.1583\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8190, lr=0.000452, perplexity_token=2.2683]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8190128750081829, 'train/perplexity_token': 2.2682597637176514, 'val/ce_loss_token': 0.7699208240956068, 'val/perplexity_token': 2.159595251083374, 'learning_rate': 0.00045214071078463635}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 16500):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8190\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.2683\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7699\n",
      "    â””â”€â”€ perplexity_token: 2.1596\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8176, lr=0.000439, perplexity_token=2.2651]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8176024276139799, 'train/perplexity_token': 2.2650628089904785, 'val/ce_loss_token': 0.7754874136298895, 'val/perplexity_token': 2.1716504096984863, 'learning_rate': 0.000439137975821056}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 17000):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8176\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.2651\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7755\n",
      "    â””â”€â”€ perplexity_token: 2.1717\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8161, lr=0.000426, perplexity_token=2.2618]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8161478764663035, 'train/perplexity_token': 2.261770486831665, 'val/ce_loss_token': 0.7698382511734962, 'val/perplexity_token': 2.159416913986206, 'learning_rate': 0.0004260022881512363}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 17500):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8161\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.2618\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7698\n",
      "    â””â”€â”€ perplexity_token: 2.1594\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ss_token=0.8147, lr=0.000413, perplexity_token=2.2586]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "Using default generation config...\n",
      "Generating with greedy search...\n",
      "wandb metrics being logged:  {'train/ce_loss_token': 0.8147241976696759, 'train/perplexity_token': 2.2585527896881104, 'val/ce_loss_token': 0.7988059241324663, 'val/perplexity_token': 2.2228851318359375, 'learning_rate': 0.00041275324125568017}\n",
      "\n",
      "ðŸ“Š Metrics (Epoch 18000):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ ce_loss_token: 0.8147\n",
      "â”‚   â””â”€â”€ perplexity_token: 2.2586\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ ce_loss_token: 0.7988\n",
      "    â””â”€â”€ perplexity_token: 2.2229\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training LM]:  44%|â–ˆâ–ˆâ–ˆâ–‰     | 18016/40669 [45:49<58:11,  6.49it/s, acc_step=1/1, ce_loss_token=0.8147, lr=0.000412, perplexity_token=2.2585]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#trainer._validate_epoch(val_loader)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ocean/projects/cis250019p/sfragara/lstm/trainers/GPT_trainer.py:90\u001b[0m, in \u001b[0;36mGPT_Trainer.train_epoch\u001b[0;34m(self, train_dataloader, val_dataloader)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Only update weights after accumulating enough gradients\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m gradient_accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# Only step scheduler here if it's not ReduceLROnPlateau\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler, torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau):\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:416\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    414\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 416\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:314\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    315\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:314\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    315\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.model.train()\n",
    "\n",
    "#trainer._validate_epoch(val_loader)\n",
    "trainer.train_epoch(\n",
    "    train_dataloader=train_loader,\n",
    "    val_dataloader=val_loader,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
